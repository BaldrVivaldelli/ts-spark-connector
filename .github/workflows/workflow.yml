name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  unit:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5

      - uses: actions/setup-node@v5
        with:
          node-version: 20
          cache: npm

      # üëá Asegura netcat y crea la carpeta de salida montada como /data/dest
      - name: Prepare runner
        run: |
          sudo apt-get update && sudo apt-get install -y netcat-openbsd
          mkdir -p example_data/dest

      - name: Boot Spark
        run: docker compose -f docker-compose.yml up -d spark

      - name: Wait for Spark
        run: |
          for i in {1..60}; do
            if nc -z 127.0.0.1 15002; then
              echo "‚úÖ Spark is up!"
              exit 0
            fi
            echo "‚è≥ Waiting for Spark... ($i/60)"
            sleep 2
          done
          echo "‚ùå Spark did not start in time"
          docker compose -f docker-compose.yml logs spark
          exit 1

      # Si tu cliente Node se conecta al Spark del host, estas vars ayudan
      - run: npm ci
        env:
          SPARK_CONNECT_HOST: 127.0.0.1
          SPARK_CONNECT_PORT: 15002
      - run: npm run typecheck --if-present
      - run: npm run lint --if-present
      - run: npm test
        env:
          SPARK_CONNECT_HOST: 127.0.0.1
          SPARK_CONNECT_PORT: 15002

  e2e:
    needs: unit
    runs-on: ubuntu-latest
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@v5

      # üëá Igual que arriba: crear carpeta de salida y asegurar nc
      - name: Prepare runner
        run: |
          sudo apt-get update && sudo apt-get install -y netcat-openbsd
          mkdir -p example_data/dest

      - name: Boot Spark
        run: docker compose -f docker-compose.yml up -d spark

      - name: Wait for Spark
        run: |
          for i in {1..60}; do
            if nc -z 127.0.0.1 15002; then
              echo "‚úÖ Spark is up!"
              exit 0
            fi
            echo "‚è≥ Waiting for Spark... ($i/60)"
            sleep 2
          done
          echo "‚ùå Spark did not start in time"
          docker compose -f docker-compose.yml logs spark
          exit 1

      # ‚ùå Ya no hace falta ivy2 si horneaste el JAR de Avro en la imagen
      # - name: Create ivy2 directory
      #   run: mkdir -p ivy2

      # ‚¨áÔ∏è Si tus E2E corren en el HOST (Node en runner):
      - name: Run E2E tests (host)
        run: npm run test:e2e
        env:
          SPARK_CONNECT_HOST: 127.0.0.1
          SPARK_CONNECT_PORT: 15002

      # ‚¨áÔ∏è O, si tus E2E corren dentro de contenedores (test:docker):
      #    Aseg√∫rate de que ese contenedor use spark:15002 como host.
      # - name: Run E2E tests with Docker
      #   run: npm run test:docker
      #   env:
      #     SPARK_CONNECT_HOST: spark
      #     SPARK_CONNECT_PORT: 15002

      - name: Clean up (always)
        if: always()
        run: |
          docker compose -f docker-compose.yml logs spark || true
          docker compose -f docker-compose.yml down -v || true
